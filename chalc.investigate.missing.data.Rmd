---
title: "Chalcophaps investigate missing data"
author: "Devon DeRaad"
date: "11/19/2020"
output: html_document
---

```{r}
#
#investigate missing data in the chlacophaps dataset

#devtools::install_github("DevonDeRaad/RADstackshelpR")
library(RADstackshelpR)

#check out what's going on with missingness between samples
vcf<-vcfR::read.vcfR("~/Desktop/chalcophaps.rad/m3.vcf")
m<-missing.by.sample(vcf)
```

```{r}
missing.by.snp(vcf)
#we have 41 samples, with 4664 SNPs retained at 60% completeness, and 346 SNPs retained at 80% completeness
```

#try a light filtering scheme
```{r}
light.vcf<-missing.by.sample(vcf, cutoff=.9)
missing.by.snp(light.vcf)
#after light filtering, we retain 38 samples, with 5694 SNPs at 60% complete, and 376 SNPs at 80% complete
#the strongly bimodal distribution of missing data by sample indicates potential batch effect or just bimodal sequencing outcomes

#we could use the 60% cutoff dataset, which has 5694 SNPs, but then 8/38 samples have > 80% missing data and will potentially have wonky inferences made about their ancestry.
#or we could use the 80% cutoff datset and have only 376 SNPs to use for downstream inference.
```

#try aggressively filtering low data samples
```{r}
vcf.agg<-missing.by.sample(vcf, cutoff = .85)
missing.by.snp(vcf.agg)
#surprisingly, removing the most missing samples isn't accounting for this bimodality, and isn't fixing our problem
#we are reduced to 29 samples, and our missing data problem hasn't really gotten better
```


```{r}
#I feel relatively confident that this is a batch effect because the samples driving it
#are not simply the ones with the most missing data 
#I think this means that even though the samples were sequenced a good amount, the loci are largely non-overlapping between different size selection batches. Would need lab work info to confirm.
#it is only after filtering to 60% missing data that the batch effect appears
#Need to drop the samples that are missing data outliers after 60% filtering
vcf.60<-missing.by.snp(vcf, cutoff=.6)
#shows me the list of the 10 problem samples
m<-missing.by.sample(vcf.60)

#subset the vcf to remove these 10 samples only
vcf@gt<-vcf@gt[,colnames(vcf@gt) != "Chalc.indi.WAM.22872" & colnames(vcf@gt) != "Chalc.indi.AMNH.21441" & colnames(vcf@gt) != "Chalc.indi.CAS.777" & colnames(vcf@gt) != "Chalc.indi.ANWC.B55964" & colnames(vcf@gt) != "Chalc.indi.AMNH.21534" 
               & colnames(vcf@gt) != "Chalc.indi.AMNH.21572" & colnames(vcf@gt) != "Chalco.step.KU.27832" & colnames(vcf@gt) != "Chalco.step.KU.12228" & colnames(vcf@gt) != "Chalco.step.WAM.26645" & colnames(vcf@gt) != "Chalc.indi.AMNH.21615"]

missing.by.snp(vcf)

#by removing potential batch effect samples, we retain 31 samples with 10846 SNPs at 60% complete, 3912 SNPs at 80% complete. We have gotten rid of the bimodality. Our most missing data sample at 80% complete cutoff, is nearly 80% missing, which is still too high. Another round of filtering to remove the 4 outlier samples is necessary

```

```{r}
sampling<-read.csv("~/Desktop/chalcophaps.rad/chalc.sampling.csv")

new.sampling<-sampling[sampling$id %in% colnames(vcf@gt),]

new.sampling[,c(1,9,10)]

```



